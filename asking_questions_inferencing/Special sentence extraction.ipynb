{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Sentence Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can generate the concept map, and calculate the cognitive load per sentence, and display text blurbs in order of increasing cognitive load as we traverse the created learning path, let's look at pulling special types of sentences from the text. When a new concept is encountered, it must be introduced to the student in some way. Based on the student's input of what concepts they are familiar with, further concepts may be introduced in terms of known concepts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#filename = 'A Mind For Numbers_ How to Excel at Math and Science (Even If You Flunked Algebra)'\n",
    "#filename = 'animal_kingdom_wiki'\n",
    "filename = 'wiki_human_digestive_system'\n",
    "\n",
    "concepts = {}\n",
    "import pickle\n",
    "# Loading extracted concepts from file (see concept_extraction.ipynb)\n",
    "#concepts = {'sents':sents,'rawtxt':rawtxt,'sent_to_npflat':sent_to_npflat,'sent_to_tags':sent_to_tags,'sent_to_ltags':sent_to_ltags,'np_to_sent':np_to_sent,'Conceptdata':Conceptdata}\n",
    "with open('../processed_data/'+filename +'concepts.pickle', 'rb') as f:\n",
    "    concepts = pickle.load(f)\n",
    "\n",
    "# Loading idf dictionary (see Build_IDF_dictionary.ipynb)\n",
    "with open('../processed_data/'+'idf_dict.pickle','rb') as f1:\n",
    "    idf_dict =pickle.load(f1)\n",
    "\n",
    "sents = concepts['sents']\n",
    "rawtxt = concepts['rawtxt']\n",
    "sent_to_npflat = concepts['sent_to_npflat']\n",
    "sent_to_tags= concepts['sent_to_tags']\n",
    "sent_to_ltags = concepts['sent_to_ltags']\n",
    "np_to_sent = concepts['np_to_sent']\n",
    "Conceptdata = concepts['Conceptdata']\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "def get_idf(wrd,totaldocs=10788):\n",
    "    wrd = wrd.lower()\n",
    "    return idf_dict.get(wrd,math.log(totaldocs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cl_per_sentence(sent_to_npflat,maxidf=9.1,include_pronouns=True):\n",
    "    sent_to_clt = []\n",
    "    for i in range(len(sent_to_npflat)):\n",
    "        npinsent = sent_to_npflat[i]\n",
    "        clt= 0\n",
    "        for np in npinsent:\n",
    "            tokens = np.split(' ')\n",
    "            idf = 0\n",
    "            for t in tokens:\n",
    "                if t not in stop_words:\n",
    "                    idf = idf + get_idf(t)/len(tokens)\n",
    "            if (idf>=maxidf):\n",
    "                clt = clt + 1\n",
    "        if include_pronouns is True:\n",
    "            pnpinsent = len([tok for tok in sent_to_ltags[24] if tok[1]=='PRP'])\n",
    "            clt = clt + pnpinsent\n",
    "        sent_to_clt.append(clt)\n",
    "    return sent_to_clt\n",
    "\n",
    "def plot_clt():\n",
    "    \n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.xlabel('document sentence #')\n",
    "    plt.ylabel('Load added to working memory by sentence')\n",
    "    plt.title('Cognitive Load for '+filename)\n",
    "    plt.plot(list(range(1,len(sent_to_npflat)+1)),calc_cl_per_sentence(sent_to_npflat),drawstyle='steps')\n",
    "    plt.savefig('cltfig1.png')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininum cognitive load sentence:  Digestion involves the breakdown of food into smaller and smaller components, until they can be absorbed and assimilated into the body.\n",
      "Maximum cognitive load sentence:  This is achieved in the duodenum by the addition of bile from the gall bladder combined with the bicarbonate secretions from the pancreatic duct and also from secretions of bicarbonate-rich mucus from duodenal glands known as Brunner's glands.\n"
     ]
    }
   ],
   "source": [
    "sent_to_clt = calc_cl_per_sentence(sent_to_npflat)\n",
    "print('Mininum cognitive load sentence: ',sents[sent_to_clt.index(min(sent_to_clt))])\n",
    "print('Maximum cognitive load sentence: ',sents[sent_to_clt.index(max(sent_to_clt))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to get blurbs for two concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def calc_clt_blurb_order(tuplist):\n",
    "    tup_to_clt = {}\n",
    "    for tup in tuplist:\n",
    "        blurb_clt = 0\n",
    "        for i in range(tup[0],tup[1]+1):\n",
    "            blurb_clt = blurb_clt + sent_to_clt[i]\n",
    "        tup_to_clt[tup] = blurb_clt\n",
    "    tup_to_clt = pd.Series(tup_to_clt)\n",
    "    tup_to_clt.sort_values(ascending=True)\n",
    "    return list(tup_to_clt.sort_values(ascending=True).index)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_indices(np1,np2,max_distance=3):\n",
    "    sents1 = np_to_sent[np1]\n",
    "    sents2 = np_to_sent[np2]\n",
    "    ind1 = 0\n",
    "    ind2 = 0\n",
    "    tuplist = []\n",
    "    lensents1 = len(sents1)\n",
    "    #print(lensents1)\n",
    "    lensents2 = len(sents2)\n",
    "    #print(lensents2)\n",
    "    while(ind1<lensents1 and ind2 <lensents2):\n",
    "        #print(ind1,ind2)\n",
    "        if (sents1[ind1]<sents2[ind2]):\n",
    "            #print('sent1 less than sent2')\n",
    "            if sents2[ind2]-sents1[ind1]<=max_distance:\n",
    "                tuplist.append((sents1[ind1],sents2[ind2]))\n",
    "                ind1 = ind1+1\n",
    "                ind2 = ind2 + 1\n",
    "            else:\n",
    "                #ind1 = bs.bisect_left(sents1,sents2[ind2])\n",
    "                ind1 = ind1 + 1\n",
    "        elif (sents1[ind1]>sents2[ind2]):\n",
    "            #print('sent2 less than sent1')\n",
    "            if sents1[ind1]-sents2[ind2] <= max_distance:\n",
    "                tuplist.append((sents2[ind2],sents1[ind1]))\n",
    "                ind1 = ind1 + 1\n",
    "                ind2 = ind2 + 1\n",
    "            else:\n",
    "                #ind2 = bs.bisect_left(sents2,sents1[ind1])\n",
    "                ind2 = ind2 + 1\n",
    "        else:\n",
    "            tuplist.append((sents1[ind1],sents2[ind2]))\n",
    "            ind1 = ind1+1\n",
    "            ind2 = ind2+1\n",
    "    return tuplist\n",
    "\n",
    "def get_blurbs(np1,np2,max_distance=3):\n",
    "    blurblist = []\n",
    "    tuplist = calc_clt_blurb_order(get_sentence_indices(np1,np2,max_distance))\n",
    "    print(tuplist)\n",
    "    for t in tuplist:\n",
    "        blurb = []\n",
    "        print(t)\n",
    "        blurb = ' '.join(sents[t[0]:t[1]+1]).replace('\\n', ' ').replace('\\r', '')\n",
    "        print(blurb)\n",
    "        blurblist.append(blurb)\n",
    "    return tuplist, blurblist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept</th>\n",
       "      <th>Occurence</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Sdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>food</td>\n",
       "      <td>[1, 3, 4, 6, 7, 10, 11, 15, 18, 25, 44, 46, 49...</td>\n",
       "      <td>41</td>\n",
       "      <td>0.254933</td>\n",
       "      <td>0.233146</td>\n",
       "      <td>0.202711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>stomach</td>\n",
       "      <td>[8, 9, 12, 13, 26, 77, 108, 127, 129, 139, 141...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.505914</td>\n",
       "      <td>0.473315</td>\n",
       "      <td>0.259822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>small intestine</td>\n",
       "      <td>[14, 15, 25, 68, 161, 163, 205, 220, 240, 243,...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.672285</td>\n",
       "      <td>0.740169</td>\n",
       "      <td>0.265817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mouth</td>\n",
       "      <td>[4, 6, 20, 22, 32, 34, 38, 41, 42, 43, 44, 53,...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.251661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>esophagus</td>\n",
       "      <td>[8, 13, 66, 89, 115, 119, 122, 125, 126, 127, ...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.395527</td>\n",
       "      <td>0.376404</td>\n",
       "      <td>0.205135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>duodenum</td>\n",
       "      <td>[10, 78, 145, 150, 159, 161, 203, 207, 208, 22...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.648876</td>\n",
       "      <td>0.208970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>digestion</td>\n",
       "      <td>[0, 1, 2, 3, 7, 9, 10, 11, 12, 15, 17, 18, 25,...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.210674</td>\n",
       "      <td>0.050562</td>\n",
       "      <td>0.235680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>bile</td>\n",
       "      <td>[176, 192, 194, 195, 200, 201, 203, 205, 206, ...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.590556</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.043195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>liver</td>\n",
       "      <td>[0, 19, 147, 176, 179, 180, 181, 183, 188, 189...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.516115</td>\n",
       "      <td>0.530899</td>\n",
       "      <td>0.198811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tongue</td>\n",
       "      <td>[0, 5, 11, 20, 33, 48, 49, 58, 59, 61, 64, 79,...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.159176</td>\n",
       "      <td>0.168539</td>\n",
       "      <td>0.088110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Concept                                          Occurence  \\\n",
       "11              food  [1, 3, 4, 6, 7, 10, 11, 15, 18, 25, 44, 46, 49...   \n",
       "34           stomach  [8, 9, 12, 13, 26, 77, 108, 127, 129, 139, 141...   \n",
       "52   small intestine  [14, 15, 25, 68, 161, 163, 205, 220, 240, 243,...   \n",
       "21             mouth  [4, 6, 20, 22, 32, 34, 38, 41, 42, 43, 44, 53,...   \n",
       "33         esophagus  [8, 13, 66, 89, 115, 119, 122, 125, 126, 127, ...   \n",
       "37          duodenum  [10, 78, 145, 150, 159, 161, 203, 207, 208, 22...   \n",
       "8          digestion  [0, 1, 2, 3, 7, 9, 10, 11, 12, 15, 17, 18, 25,...   \n",
       "463             bile  [176, 192, 194, 195, 200, 201, 203, 205, 206, ...   \n",
       "7              liver  [0, 19, 147, 176, 179, 180, 181, 183, 188, 189...   \n",
       "3             tongue  [0, 5, 11, 20, 33, 48, 49, 58, 59, 61, 64, 79,...   \n",
       "\n",
       "     Frequency      Mean    Median      Sdev  \n",
       "11          41  0.254933  0.233146  0.202711  \n",
       "34          38  0.505914  0.473315  0.259822  \n",
       "52          30  0.672285  0.740169  0.265817  \n",
       "21          27  0.250000  0.185393  0.251661  \n",
       "33          26  0.395527  0.376404  0.205135  \n",
       "37          23  0.617978  0.648876  0.208970  \n",
       "8           23  0.210674  0.050562  0.235680  \n",
       "463         21  0.590556  0.595506  0.043195  \n",
       "7           19  0.516115  0.530899  0.198811  \n",
       "3           18  0.159176  0.168539  0.088110  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conceptdata.sort_values(by=['Frequency'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(62418, 62419), (62540, 62541), (65774, 65774), (65881, 65881), (68995, 68996), (89267, 89267), (101567, 101568), (114753, 114754)]\n",
      "(62418, 62419)\n",
      "His book Philosophiæ Naturalis Principia Mathematica (\"Mathematical Principles of Natural Philosophy\"), first published in 1687, laid the foundations of classical mechanics. Newton also made seminal contributions to optics, and shares credit with Gottfried Wilhelm Leibniz for developing the infinitesimal calculus.\n",
      "(62540, 62541)\n",
      "In this work, Newton stated the three universal laws of motion. Together, these laws describe the relationship between any object, the forces acting upon it and the resulting motion, laying the foundation for classical mechanics.\n",
      "(65774, 65774)\n",
      "In classical mechanics, Newton's third law implies that active and passive gravitational mass must always be identical (or at least proportional), but the classical theory offers no compelling reason why the gravitational mass has to equal the inertial mass.\n",
      "(65881, 65881)\n",
      "In classical mechanics, according to Newton's second law, we say that a body has a mass m if, at any instant of time, it obeys the equation of motion where F is the resultant force acting on the body and a is the acceleration of the body's centre of mass.\n",
      "(68995, 68996)\n",
      "In classical mechanics, for a body with constant mass, the (vector) acceleration of the body's center of mass is proportional to the net force vector (i.e. sum of all forces) acting on it (Newton's second law): where F is the net force acting on the body, m is  the mass of the body, and a is the center-of-mass acceleration.\n",
      "(89267, 89267)\n",
      "[19] The modified momentum, obeys Newton's second law: Within the domain of classical mechanics, relativistic momentum closely approximates Newtonian momentum: at low velocity, γm0v is approximately equal to m0v, the Newtonian expression for momentum.\n",
      "(101567, 101568)\n",
      "Newton extended Descartes' mathematics by inventing calculus (contemporaneously with Leibniz). He provided a comprehensive formulation of classical mechanics and investigated light and optics.\n",
      "(114753, 114754)\n",
      "The acceleration     a   {\\displaystyle a}   is according to Newton's second law bound to a force     F   {\\displaystyle F}   by the proportionality given by the mass     m   {\\displaystyle m}  . In classical mechanics of rigid bodies there are no forces associated with the higher derivatives of the path, nevertheless not only the physiological effects of jerk, but also oscillations and deformation propagation along and in non-ideally rigid bodies, require various techniques for controlling motion to avoid the resulting destructive forces.\n"
     ]
    }
   ],
   "source": [
    "tuplist, blurblist = get_blurbs('bile','newton',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'classical mechanic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7a516a4d7327>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# printing ratio of concept's be sentences to all of the concept's sentences, and to all sentences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbe_sents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp_to_sent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classical mechanic'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'be'\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mltag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mltag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent_to_ltags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbe_sents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbe_sents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_to_sent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classical mechanic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbe_sents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'classical mechanic'"
     ]
    }
   ],
   "source": [
    "# printing be lemma sentences for one concept within 2 words before or after the concept word, and in present/past simple tense.\n",
    "# printing ratio of concept's be sentences to all of the concept's sentences, and to all sentences\n",
    "\n",
    "be_sents = [s for s in np_to_sent['classical mechanic'] if 'be' in [ltag[0] for ltag in sent_to_ltags[s]]]\n",
    "print(be_sents,len(be_sents)/len(np_to_sent['classical mechanic']),len(be_sents)/len(sents))\n",
    "\n",
    "be_sents_clt = pd.Series([sent_to_clt[s] for s in be_sents],be_sents)\n",
    "be_sents_clt.sort_values( ascending = True,inplace = True)\n",
    "be_sents_clt\n",
    "\n",
    "for s in be_sents_clt.index:\n",
    "    print(s,': ',sents[s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the place of the concept in the sentence (assuming only one occurence, or working with only the first occurence)\n",
    "# get the window of ltags to consider\n",
    "# get only VBP,VBZ,VBD forms of be in that window\n",
    "# explore ones that only contain WDT, WP, WP$\n",
    "\n",
    "\n",
    "def get_def_sentence_indices(cncpt,window=2,be_tagforms = ['VBP','VBZ','VBD'],that_tagforms = ['WDT','WP','WP$','TO']):\n",
    "    def_sents_index = []\n",
    "    cncpt_first = cncpt.split(' ')[0]\n",
    "    cncpt_last = cncpt.split(' ')[-1]\n",
    "    for s in np_to_sent[cncpt]:\n",
    "        lemmlist = [ltag[0] for ltag in sent_to_ltags[s]]\n",
    "        taglist = [ltag[1] for ltag in sent_to_ltags[s]]\n",
    "        cncptindex = lemmlist.index(cncpt_first)\n",
    "        lemmwindow = lemmlist[max(0,cncptindex-window):min(len(lemmlist),cncptindex+window+len(cncpt.split(' ')))] \n",
    "        tagwindow = taglist[max(0,cncptindex-window):min(len(lemmlist),cncptindex+window+len(cncpt.split(' ')))] \n",
    "                \n",
    "        if ('be' in lemmwindow):\n",
    "            beindex = lemmwindow.index('be')\n",
    "            if tagwindow[beindex] in be_tagforms:\n",
    "                if len(set(that_tagforms).intersection(set(taglist)))>0:\n",
    "                    def_sents_index.append(s)\n",
    "    return(def_sents_index)\n",
    "\n",
    "# index errors if item not in list.                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "The mouth is the first part of the upper gastrointestinal tract and is equipped with several structures that begin the first processes of digestion.\n",
      "Underlying the mucous membrane in the mouth is a thin layer of smooth muscle tissue and the loose connection to the membrane gives it its great elasticity.\n",
      "A common gum disease in the mouth is gingivitis which is caused by bacteria in plaque.\n"
     ]
    }
   ],
   "source": [
    "slist = get_def_sentence_indices('mouth')\n",
    "for s in slist:\n",
    "    print(sents[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get instructing sentences that take the form of do this, then do that. (method)\n",
    "\n",
    "# get sentences with qualifiers (rules, assumptions)\n",
    "\n",
    "# consider extracting lists from np extractor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167                                               fabric\n",
       "15                                               example\n",
       "380                                                 time\n",
       "27                                                number\n",
       "483                                                 year\n",
       "16                                                    cm\n",
       "20                                                  inch\n",
       "271                                                place\n",
       "288                                                 edge\n",
       "283                                                  end\n",
       "0                                                   side\n",
       "122                                                 work\n",
       "1336                                                term\n",
       "4644                                               woman\n",
       "1360                                              result\n",
       "1017                                              people\n",
       "1761                                                part\n",
       "458                                                 case\n",
       "438                                                  way\n",
       "1494                                              system\n",
       "1035                                                area\n",
       "152                                                piece\n",
       "73                                                  type\n",
       "686                                                water\n",
       "58                                                 value\n",
       "292                                                  pin\n",
       "123                                                point\n",
       "180                                                 line\n",
       "732                                                child\n",
       "128                                              pattern\n",
       "                               ...                      \n",
       "152957                                        black site\n",
       "152956                             group withholdapadues\n",
       "152955                            dissident psychologist\n",
       "152954                                   norman anderson\n",
       "152952                                  effective august\n",
       "152935                    chicago attorney david hoffman\n",
       "152951    deputy chief executive officer michael honaker\n",
       "152950                                    rhea farberman\n",
       "152949                                      other firing\n",
       "152948                                      apa official\n",
       "152947                                               dod\n",
       "152946                                  principal motive\n",
       "152945                              important department\n",
       "152944                                         apa issue\n",
       "152943                                  defense official\n",
       "152941                                 terrorism suspect\n",
       "152940                             ethical justification\n",
       "152939                                      apa relating\n",
       "152937                                   542-page report\n",
       "152936                        george bush administration\n",
       "152745                        representational structure\n",
       "152744                               corporate structure\n",
       "152743                                  suggested change\n",
       "152546                                  unaddressed year\n",
       "152539                                    public protest\n",
       "152541                                violent expression\n",
       "152542                                wider market force\n",
       "152543                              economic competition\n",
       "152544                         cultural misunderstanding\n",
       "152545                            economic disproportion\n",
       "Name: Concept, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conceptdata.sort_values(by='Frequency',ascending=False).head(100000)['Concept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('newton'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "9 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-cdcad56c4574>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 9 is not in list"
     ]
    }
   ],
   "source": [
    "[1,2,3,4].index(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
